import streamlit as st
import os
import requests
import json
from openai import OpenAI
from dotenv import load_dotenv
from datetime import datetime
import pandas as pd
import io
import yaml
from yaml.loader import SafeLoader
import hashlib
import time
from collections import defaultdict
import plotly.express as px
import plotly.graph_objects as go
from supabase_config import get_supabase_client

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()

# --- Configura√ß√µes de Autentica√ß√£o ---
def carregar_config_usuarios():
    """Carrega a configura√ß√£o de usu√°rios do arquivo config.yaml"""
    try:
        with open('config.yaml') as file:
            return yaml.load(file, Loader=SafeLoader)
    except FileNotFoundError:
        st.error("Arquivo de configura√ß√£o de usu√°rios n√£o encontrado!")
        return None

def verificar_credenciais(email, password):
    """Verifica se as credenciais do usu√°rio s√£o v√°lidas usando Supabase Auth"""
    try:
        # O cliente Supabase j√° deve estar inicializado globalmente
        response = supabase.auth.sign_in_with_password({"email": email, "password": password})
        if response.user:
            return True
    except Exception as e:
        # Tratar erros espec√≠ficos do Supabase se necess√°rio, ex: usu√°rio n√£o encontrado, senha inv√°lida
        st.error(f"Erro de autentica√ß√£o: {e}")
        return False
    return False

def inicializar_autenticacao():
    """Inicializa o estado de autentica√ß√£o"""
    if 'autenticado' not in st.session_state:
        st.session_state.autenticado = False
    if 'username' not in st.session_state: # Manter 'username' para consist√™ncia interna, mas ele guardar√° o email
        st.session_state.username = None
    if 'login_success' not in st.session_state:
        st.session_state.login_success = False

def login():
    """Interface de login"""
    st.title("üîê Login Mencare IA")
    
    # Se o login foi bem-sucedido, mostrar mensagem e redirecionar
    if st.session_state.login_success:
        st.success("Login realizado com sucesso!")
        st.session_state.login_success = False # Resetar para evitar loop
        st.session_state.autenticado = True
        st.rerun()
        return
    
    with st.form("login_form"):
        email = st.text_input("Email") # Alterado de Usu√°rio para Email
        password = st.text_input("Senha", type="password")
        submit = st.form_submit_button("Entrar")
        
        if submit:
            if verificar_credenciais(email, password):
                st.session_state.username = email # Armazenar o email como 'username'
                st.session_state.login_success = True
                st.rerun()
            else:
                st.error("Email ou senha inv√°lidos!")

# --- Configura√ß√µes Iniciais ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# Configura√ß√£o de tokens por plataforma
TOKENS_POR_PLATAFORMA = {
    "Disparo de WhatsApp": 150,
    "Email Marketing": 600,
    "Conte√∫do para Redes Sociais (Feed)": 300,
    "Conte√∫do para Redes Sociais (Stories)": 200,
    "Copy para SMS": 100       
}

# Adicionar ap√≥s as configura√ß√µes iniciais
METRICAS_POR_PLATAFORMA = {
    "Disparo de WhatsApp": {
        "respostas": 0,
        "taxa_conversao": 0.0,
        "total_disparos": 0
    },
    "Email Marketing": {
        "taxa_abertura": 0.0,
        "taxa_clique": 0.0,
        "taxa_conversao": 0.0,
        "total_envios": 0
    },
    "Conte√∫do para Redes Sociais (Feed)": {
        "compartilhamentos": 0,
        "likes": 0,
        "comentarios": 0,
        "alcance": 0
    },
    "Conte√∫do para Redes Sociais (Stories)": {
        "visualizacoes": 0,
        "respostas": 0,
        "cliques": 0,
        "alcance": 0
    },
    "Copy para SMS": {
        "taxa_clique": 0.0,
        "taxa_conversao": 0.0,
        "total_envios": 0
    }
}

# Adicionar ap√≥s as configura√ß√µes iniciais
TAGS_PREDEFINIDAS = {
    "Tipo de Neg√≥cio": [
        "E-commerce",
        "Servi√ßos",
        "Produtos F√≠sicos",
        "Digital",
        "B2B",
        "B2C"
    ],
    "Setor": [
        "Sa√∫de",
        "Educa√ß√£o",
        "Tecnologia",
        "Moda",
        "Alimenta√ß√£o",
        "Finan√ßas",
        "Imobili√°rio",
        "Outros"
    ],
    "Objetivo": [
        "Vendas",
        "Leads",
        "Engajamento",
        "Branding",
        "Fideliza√ß√£o",
        "Educa√ß√£o"
    ],
    "P√∫blico": [
        "Jovens",
        "Adultos",
        "Profissionais",
        "Empres√°rios",
        "Estudantes",
        "Fam√≠lias"
    ]
}

# Verificar se as configura√ß√µes essenciais est√£o presentes
if not OPENAI_API_KEY:
    st.error("Chave da API da OpenAI n√£o configurada. Verifique o arquivo .env.")
    st.stop()
if not (SUPABASE_URL and SUPABASE_KEY):
    st.warning("Configura√ß√µes do Supabase incompletas. A funcionalidade de salvar no banco de dados pode n√£o funcionar.")

# Inicializar cliente OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

# Inicializar cliente Supabase
supabase = get_supabase_client()

# Inicializar autentica√ß√£o
inicializar_autenticacao()

# --- Fun√ß√µes Auxiliares ---

def gerar_copy_openai(plataforma, objetivo, publico_alvo, produto_servico, tom_de_voz, cta, informacoes_adicionais=""):
    # Obter o limite de tokens para a plataforma selecionada
    max_tokens = TOKENS_POR_PLATAFORMA.get(plataforma, 300)
    
    # Criar barra de progresso
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Atualizar status - Preparando prompt
        status_text.text("üîÑ Preparando prompt...")
        progress_bar.progress(10)
        time.sleep(0.5)  # Pequena pausa para feedback visual
        
        prompt = f"""
        Voc√™ √© um copywriter especialista em marketing digital com mais de 20 anos de experi√™ncia.
        Sua tarefa √© gerar uma copy persuasiva e eficaz para a plataforma especificada.
        IMPORTANTE: Mantenha a copy dentro do limite de {max_tokens} tokens.

        Plataforma: {plataforma}
        Objetivo da Copy: {objetivo}
        P√∫blico-Alvo: {publico_alvo}
        Produto/Servi√ßo a ser promovido: {produto_servico}
        Tom de Voz desejado: {tom_de_voz}
        Call to Action (CTA): {cta}
        {f"Informa√ß√µes Adicionais: {informacoes_adicionais}" if informacoes_adicionais else ""}

        Instru√ß√µes espec√≠ficas para a plataforma '{plataforma}':
        """

        # Atualizar status - Configurando modelo
        status_text.text("‚öôÔ∏è Configurando modelo de IA...")
        progress_bar.progress(30)
        time.sleep(0.5)

        if plataforma == "Disparo de WhatsApp":
            prompt += """
            - Seja breve, direto e pessoal.
            - Use emojis com modera√ß√£o para aumentar o engajamento.
            - Ideal para mensagens curtas e impacto r√°pido.
            - Inicie de forma amig√°vel.
            - Deixe o CTA claro e f√°cil de seguir.
            - Considere o uso de gatilhos mentais como urg√™ncia ou escassez, se aplic√°vel.
            """
        elif plataforma == "Email Marketing":
            prompt += """
            - Assunto do email: Crie um assunto curto, chamativo e que gere curiosidade.
            - Corpo do email:
                - Comece com uma sauda√ß√£o personalizada, se poss√≠vel.
                - Desenvolva o problema ou necessidade do p√∫blico-alvo.
                - Apresente o produto/servi√ßo como a solu√ß√£o.
                - Destaque os principais benef√≠cios.
                - Use par√°grafos curtos e boa formata√ß√£o (negrito, listas).
                - O CTA deve ser claro e vis√≠vel (pode ser um link ou bot√£o).
            - Pode ser mais longo que outras plataformas, mas mantenha o foco.
            """
        elif plataforma == "Conte√∫do para Redes Sociais (Feed)":
            prompt += """
            - Adapte a linguagem para a rede social espec√≠fica (ex: Instagram mais visual, LinkedIn mais profissional).
            - Use hashtags relevantes (sugira 3-5 hashtags).
            - Incentive o engajamento (perguntas, enquetes, pedir coment√°rios).
            - Imagens/v√≠deos s√£o importantes, mas a copy precisa ser atrativa por si s√≥.
            - Pode contar uma pequena hist√≥ria ou dar uma dica r√°pida.
            """
        elif plataforma == "Conte√∫do para Redes Sociais (Stories)":
            prompt += """
            - Formato curto e din√¢mico.
            - Use texto conciso e chamativo.
            - Ideal para enquetes, perguntas r√°pidas, "arrasta para cima".
            - Pode ser mais informal.
            - O CTA deve ser imediato.
            """
        elif plataforma == "Copy para SMS":
            prompt += """
            - Extremamente curto e objetivo (limite de caracteres, geralmente 160).
            - CTA direto e, se poss√≠vel, com link encurtado.
            - Use abrevia√ß√µes com cautela para n√£o prejudicar a clareza.
            - Ideal para lembretes, promo√ß√µes r√°pidas ou alertas.
            """

        prompt += "\nGere a copy abaixo:\n"

        # Atualizar status - Gerando copy
        status_text.text("ü§ñ Gerando copy com IA...")
        progress_bar.progress(50)
        time.sleep(0.5)

        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um copywriter especialista em marketing digital."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=max_tokens
        )

        # Rastrear consumo de tokens
        tokens_consumidos = response.usage.total_tokens
        salvar_consumo_tokens(tokens_consumidos, "copy", st.session_state.username) # Passar username
        
        # Atualizar status - Finalizando
        status_text.text("‚ú® Finalizando e formatando copy...")
        progress_bar.progress(90)
        time.sleep(0.5)

        copy_gerada = response.choices[0].message.content.strip()
        
        # Conclu√≠do
        status_text.text("‚úÖ Copy gerada com sucesso!")
        progress_bar.progress(100)
        time.sleep(0.5)
        
        # Limpar elementos de progresso
        progress_bar.empty()
        status_text.empty()
        
        return copy_gerada
    except Exception as e:
        # Em caso de erro
        status_text.text("‚ùå Erro ao gerar copy")
        progress_bar.progress(0)
        time.sleep(1)
        progress_bar.empty()
        status_text.empty()
        st.error(f"Erro ao contatar a OpenAI: {e}")
        return None

def salvar_no_supabase(data_to_save):
    """Salva uma copy no Supabase"""
    try:
        # Adicionar usu√°rio_id se dispon√≠vel
        if 'username' in st.session_state and st.session_state.username:
            # Buscar o ID do usu√°rio no Supabase com base no email (st.session_state.username)
            user_response = supabase.table('users').select('id').eq('email', st.session_state.username).execute()
            if user_response.data:
                data_to_save['usuario_id'] = user_response.data[0]['id']
            else:
                auth_user = supabase.auth.get_user()
                if auth_user and auth_user.user:
                    data_to_save['usuario_id'] = auth_user.user.id
                else:
                     st.warning("N√£o foi poss√≠vel obter o ID do usu√°rio autenticado para salvar a copy.")


        # Formatar dados para o Supabase
        payload = {
            "plataforma": data_to_save.get("plataforma"),
            "objetivo": data_to_save.get("objetivo"),
            "publico_alvo": data_to_save.get("publico_alvo"),
            "produto_servico": data_to_save.get("produto_servico"),
            "tom_de_voz": data_to_save.get("tom_de_voz"),
            "cta": data_to_save.get("cta"),
            "copy_gerada": data_to_save.get("copy_gerada"),
            "data_geracao": datetime.now().isoformat()
        }

        # Remover campos None
        payload = {k: v for k, v in payload.items() if v is not None}

        # Salvar no Supabase
        response = supabase.table('copies').insert(payload).execute()
        
        if response.data:
            st.success("Copy salva com sucesso no Supabase!")
            return True
        else:
            st.error("Erro ao salvar copy no Supabase.")
            return False
    except Exception as e:
        st.error(f"Erro ao salvar no Supabase: {e}")
        return False

def salvar_analise_leads(analise_data):
    """Salva a an√°lise de leads no Supabase e retorna o ID da an√°lise salva."""
    try:
        auth_user = supabase.auth.get_user()
        current_user_id = None
        if auth_user and auth_user.user:
            current_user_id = auth_user.user.id
        else:
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel salvar a an√°lise de leads.")
            return None # Retornar None em caso de falha na autentica√ß√£o

        payload = {
            "plataforma": analise_data.get("plataforma"),
            "objetivo": analise_data.get("objetivo"),
            "total_leads": analise_data.get("total_leads"), 
            "colunas": json.dumps(analise_data.get("colunas", [])),
            "analise": analise_data.get("analise"),
            "tempo_processamento": analise_data.get("tempo_processamento"),
            "resumo_estatistico": json.dumps(analise_data.get("resumo_estatistico", {})),
            "usuario_id": current_user_id,
            "data": datetime.now().isoformat()
        }

        print(f"DEBUG: Tentando salvar em analises_leads com usuario_id: {current_user_id}")
        response = supabase.table('analises_leads').insert(payload).execute()
        
        if response.data and len(response.data) > 0:
            saved_analise_id = response.data[0]['id'] # UUID da an√°lise salva
            if 'tags' in analise_data and analise_data['tags']:
                tags_para_salvar = []
                for tag_nome in analise_data['tags']:
                    categoria_tag = "Personalizada"
                    for cat, tags_list in TAGS_PREDEFINIDAS.items():
                        if tag_nome in tags_list:
                            categoria_tag = cat
                            break
                    tags_para_salvar.append({
                        "analise_id": saved_analise_id, # Usar o UUID aqui
                        "categoria": categoria_tag,
                        "tag": tag_nome,
                        "usuario_id": current_user_id 
                    })
                if tags_para_salvar:
                    tags_response = supabase.table('tags').insert(tags_para_salvar).execute()
                    if not (tags_response.data and len(tags_response.data) > 0):
                        st.warning("An√°lise salva, mas houve um erro ao salvar algumas ou todas as tags.")
            
            st.success("An√°lise e tags salvas com sucesso no Supabase!")
            return saved_analise_id # Retornar o UUID da an√°lise salva
        else:
            error_msg = response.error.message if response.error else "Erro desconhecido"
            st.error(f"Erro ao salvar an√°lise no Supabase: {error_msg}")
            return None # Retornar None em caso de falha
    except Exception as e:
        st.error(f"Erro excepcional ao salvar an√°lise: {e}")
        return None # Retornar None em caso de exce√ß√£o

def atualizar_tags_analise(analise_id, novas_tags):
    """Atualiza as tags de uma an√°lise espec√≠fica no Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel atualizar as tags.")
            return False
        user_id = auth_user.user.id

        # 1. Deletar tags antigas para esta analise_id e usuario_id (para seguran√ßa)
        delete_response = supabase.table('tags').delete().match({'analise_id': analise_id, 'usuario_id': user_id}).execute()

        # 2. Inserir novas tags
        if novas_tags:
            tags_para_inserir = []
            for tag_nome in novas_tags:
                # Determinar a categoria da tag. Por enquanto, vou usar "Personalizada"
                categoria_tag = "Personalizada" # Default
                for cat, tags_list in TAGS_PREDEFINIDAS.items():
                    if tag_nome in tags_list:
                        categoria_tag = cat
                        break
                
                tags_para_inserir.append({
                    'analise_id': analise_id,
                    'categoria': categoria_tag, # Adicionar categoria da tag
                    'tag': tag_nome,
                    'usuario_id': user_id
                })
            
            if tags_para_inserir:
                insert_response = supabase.table('tags').insert(tags_para_inserir).execute()
                if insert_response.data:
                    return True
                else:
                    st.error(f"Erro ao inserir novas tags no Supabase: {insert_response.error.message if insert_response.error else 'Erro desconhecido'}")
                    return False
        return True # Verdadeiro se n√£o havia novas tags para inserir (tags antigas foram removidas)

    except Exception as e:
        st.error(f"Erro ao atualizar tags no Supabase: {e}")
        return False

def gerar_insights_com_tags(analise_atual, tags_da_analise_atual):
    """Gera insights baseados nas tags da an√°lise, buscando no Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.info("Usu√°rio n√£o autenticado. Insights baseados em tags n√£o podem ser gerados.")
            return "Nenhum insight similar encontrado (usu√°rio n√£o autenticado)."
        user_id = auth_user.user.id
        analise_id_atual = analise_atual['id']

        if not tags_da_analise_atual:
            return "Nenhuma tag fornecida para buscar insights similares."

        # 1. Encontrar todas as analise_ids (diferentes da atual) que compartilham pelo menos uma tag com a an√°lise atual
        analises_similares_ids = set()
        for tag_nome in tags_da_analise_atual:
            response_tags_similares = supabase.table('tags')\
                .select('analise_id')\
                .eq('usuario_id', user_id)\
                .eq('tag', tag_nome)\
                .neq('analise_id', analise_id_atual)\
                .execute()
            if response_tags_similares.data:
                for item in response_tags_similares.data:
                    analises_similares_ids.add(item['analise_id'])
        
        if not analises_similares_ids:
            return "Nenhum insight similar encontrado com as tags fornecidas."

        # 2. Buscar os detalhes dessas an√°lises similares
        response_analises_similares = supabase.table('analises_leads')\
            .select('id, data, plataforma, objetivo, analise')\
            .in_('id', list(analises_similares_ids))\
            .order('data', desc=True)\
            .limit(5) .execute() # Limitar o n√∫mero de an√°lises similares para n√£o sobrecarregar

        insights_gerados = []
        if response_analises_similares.data:
            insights_gerados.append("\n### Insights de An√°lises Anteriores com Tags Similares:")
            for analise_similar_db in response_analises_similares.data:
                data_iso = analise_similar_db.get('data')
                data_formatada = str(data_iso)
                if data_iso:
                    try:
                        dt_obj = datetime.fromisoformat(data_iso.replace('Z', '+00:00').replace('+0000', '+00:00'))
                        data_formatada = dt_obj.strftime("%d/%m/%Y %H:%M:%S")
                    except ValueError:
                        try:
                            dt_obj = datetime.strptime(data_iso, "%d/%m/%Y %H:%M:%S")
                            data_formatada = dt_obj.strftime("%d/%m/%Y %H:%M:%S")
                        except ValueError:
                            pass
                
                insights_gerados.append(f"""
**Data:** {data_formatada}
**Plataforma:** {analise_similar_db.get('plataforma', 'N/A')}
**Objetivo:** {analise_similar_db.get('objetivo', 'N/A')}
**An√°lise Resumida:** {analise_similar_db.get('analise', 'N/A')[:200] + '...' if analise_similar_db.get('analise') else 'N/A'}
---""")
            return "\n".join(insights_gerados)
        else:
            return "Nenhum insight similar encontrado com as tags fornecidas."

    except Exception as e:
        st.error(f"Erro ao gerar insights com tags do Supabase: {e}")
        return "Erro ao gerar insights."

def carregar_historico_analises():
    """Carrega o hist√≥rico de an√°lises do usu√°rio atual a partir do Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel carregar o hist√≥rico de an√°lises.")
            return []

        user_id = auth_user.user.id
        
        # Buscar an√°lises do usu√°rio
        response_analises = supabase.table('analises_leads').select('*').eq('usuario_id', user_id).order('data', desc=True).execute()
        
        if response_analises.data:
            historico_com_tags = []
            for analise_db in response_analises.data:
                # Para cada an√°lise, buscar suas tags
                response_tags = supabase.table('tags').select('tag').eq('analise_id', analise_db['id']).execute()
                
                tags_da_analise = []
                if response_tags.data:
                    tags_da_analise = [item['tag'] for item in response_tags.data]
                
                # Montar o dicion√°rio da an√°lise no formato esperado
                # Convertendo campos JSON de string para dict/list se necess√°rio
                colunas = json.loads(analise_db.get('colunas', '[]')) if isinstance(analise_db.get('colunas'), str) else analise_db.get('colunas', [])
                resumo_estatistico = json.loads(analise_db.get('resumo_estatistico', '{}')) if isinstance(analise_db.get('resumo_estatistico'), str) else analise_db.get('resumo_estatistico', {})

                analise_formatada = {
                    "id": analise_db['id'],
                    "data": analise_db.get('data_criacao') or analise_db.get('data', datetime.now().strftime("%d/%m/%Y %H:%M:%S")), # Ajustar nome da coluna de data se necess√°rio
                    "plataforma": analise_db['plataforma'],
                    "objetivo": analise_db['objetivo'],
                    "total_leads": analise_db.get('total_leads'),
                    "colunas": colunas,
                    "analise": analise_db['analise'],
                    "tempo_processamento": analise_db.get('tempo_processamento'),
                    "resumo_estatistico": resumo_estatistico,
                    "tags": tags_da_analise,
                    "usuario_id": analise_db.get('usuario_id')
                }
                historico_com_tags.append(analise_formatada)
            return historico_com_tags
        else:
            return []
            
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico de an√°lises do Supabase: {e}")
        return []

def salvar_feedback(analise_id, feedback_data):
    """Salva o feedback no Supabase"""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel salvar o feedback.")
            return False
        
        current_user_id = auth_user.user.id

        # Formatar dados para o Supabase
        payload = {
            "analise_id": analise_id,
            "data": datetime.now().isoformat(), # Adicionando data do feedback
            "pontos_positivos": feedback_data.get("pontos_positivos"),
            "pontos_melhorar": feedback_data.get("pontos_melhorar"),
            "nota": feedback_data.get("nota"),
            "editado": False, 
            "ultima_edicao": datetime.now().isoformat(), # Definindo na cria√ß√£o tamb√©m
            "historico_edicoes": json.dumps([]),
            "usuario_id": current_user_id 
        }

        # Salvar no Supabase
        response = supabase.table('feedback').insert(payload).execute()
        
        if response.data:
            return True
        else:
            st.error(f"Erro ao salvar feedback: {response.error.message if response.error else 'Erro desconhecido'}")
            return False
    except Exception as e:
        st.error(f"Erro ao salvar feedback: {e}")
        return False

def editar_feedback(analise_id, novo_feedback_data):
    """Edita um feedback existente no Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel editar o feedback.")
            return False
        user_id = auth_user.user.id

        # 1. Buscar o feedback existente do usu√°rio para esta an√°lise
        # √â importante buscar pelo user_id para garantir que o usu√°rio s√≥ edite seu pr√≥prio feedback.
        response_get = supabase.table('feedback')\
            .select('*')\
            .eq('analise_id', analise_id)\
            .eq('usuario_id', user_id)\
            .order('created_at', desc=True)\
            .limit(1)\
            .maybe_single()\
            .execute()

        # Adicionar verifica√ß√£o para a pr√≥pria `response`
        if response_get is None:
            st.warning("A consulta ao Supabase para carregar feedback retornou None inesperadamente.")
            return None

        # Se .maybe_single() n√£o encontrar nada, response.data ser√° None.
        # A exce√ß√£o est√° sendo pega no bloco `except` abaixo.

        if not response_get.data:
            st.error("Feedback original n√£o encontrado para editar ou voc√™ n√£o tem permiss√£o.")
            return False
        
        feedback_atual = response_get.data
        feedback_id_db = feedback_atual['id'] # ID do registro de feedback no banco

        # 2. Preparar o hist√≥rico
        historico_edicoes_atual_str = feedback_atual.get('historico_edicoes', '[]')
        historico_edicoes_atual = []
        if isinstance(historico_edicoes_atual_str, str):
            try:
                historico_edicoes_atual = json.loads(historico_edicoes_atual_str)
            except json.JSONDecodeError:
                st.warning("Hist√≥rico de edi√ß√µes do feedback est√° mal formatado.")
        elif isinstance(historico_edicoes_atual_str, list):
            historico_edicoes_atual = historico_edicoes_atual_str
        
        feedback_anterior_para_historico = {
            "pontos_positivos": feedback_atual.get('pontos_positivos'),
            "pontos_melhorar": feedback_atual.get('pontos_melhorar'),
            "nota": feedback_atual.get('nota'),
            "ultima_edicao_original": feedback_atual.get('ultima_edicao') or feedback_atual.get('updated_at'), # Usar updated_at como fallback
            "timestamp_arquivamento": datetime.now().isoformat()
        }
        historico_edicoes_atual.append(feedback_anterior_para_historico)

        # 3. Preparar dados para atualiza√ß√£o
        dados_para_atualizar = {
            "pontos_positivos": novo_feedback_data.get("pontos_positivos"),
            "pontos_melhorar": novo_feedback_data.get("pontos_melhorar"),
            "nota": novo_feedback_data.get("nota"),
            "editado": True,
            "ultima_edicao": datetime.now().isoformat(),
            "historico_edicoes": json.dumps(historico_edicoes_atual) # Salvar como string JSON
        }

        # 4. Atualizar o feedback no Supabase usando o ID do registro de feedback
        response_update = supabase.table('feedback').update(dados_para_atualizar).eq('id', feedback_id_db).execute()

        if response_update.data:
            return True
        else:
            error_msg = response_update.error.message if response_update.error else "Erro desconhecido"
            st.error(f"Erro ao atualizar feedback no Supabase: {error_msg}")
            return False

    except Exception as e:
        st.error(f"Erro excepcional ao editar feedback: {e}")
        return False

def salvar_metricas_plataforma(plataforma, metricas_data):
    """Salva m√©tricas espec√≠ficas da plataforma no Supabase"""
    try:
        auth_user = supabase.auth.get_user()
        
        if not (auth_user and auth_user.user):
            st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel salvar m√©tricas da plataforma.")
            return False
        
        current_user_id = auth_user.user.id # Definir claramente a vari√°vel com o ID

        # Formatar dados para o Supabase
        payload = {
            "plataforma": plataforma,
            "metricas": json.dumps(metricas_data), 
            "data": datetime.now().isoformat(),
            "usuario_id": current_user_id 
        }
        
        # Log para depura√ß√£o
        print(f"DEBUG: Tentando salvar em metricas_plataforma com usuario_id: {current_user_id}, tipo: {type(current_user_id)}")

        # Salvar no Supabase
        response = supabase.table('metricas_plataforma').insert(payload).execute()
        
        if response.data:
            return True
        else:
            st.error(f"Erro ao salvar m√©tricas no Supabase: {response.error.message if response.error else 'Erro desconhecido'}")
            return False
    except Exception as e:
        st.error(f"Erro ao salvar m√©tricas da plataforma: {e}")
        return False

def analisar_leads_csv_openai(df, plataforma, objetivo, tempo_inicio_global, resumo_estatistico_global):
    progress_bar = st.progress(0)
    status_text = st.empty()
    try:
        status_text.text("üîÑ Preparando dados para an√°lise (OpenAI)... ")
        progress_bar.progress(10)
        
        colunas_relevantes = df.columns[:9]
        df_otimizado = df[colunas_relevantes].copy()
        max_linhas = 100
        if len(df_otimizado) > max_linhas:
            df_otimizado = df_otimizado.sample(n=max_linhas, random_state=42)
        df_str = df_otimizado.to_string()

        feedbacks_contexto = []
        try:
            auth_user = supabase.auth.get_user()
            if auth_user and auth_user.user:
                user_id = auth_user.user.id
                response_feedbacks = supabase.table('feedback')\
                    .select('pontos_positivos, pontos_melhorar')\
                    .eq('usuario_id', user_id)\
                    .order('created_at', desc=True)\
                    .limit(10).execute()
                if response_feedbacks and response_feedbacks.data:
                    for fb_item in response_feedbacks.data:
                        if fb_item.get('pontos_positivos') or fb_item.get('pontos_melhorar'):
                            feedbacks_contexto.append(fb_item)
                            if len(feedbacks_contexto) >= 3:
                                break
        except Exception as e_fb:
            st.warning(f"N√£o foi poss√≠vel carregar feedbacks para contexto OpenAI: {e_fb}")

        contexto_aprendizado = ""
        if feedbacks_contexto:
            contexto_aprendizado = """\
Baseado em feedbacks anteriores dos usu√°rios, considere:"""
            for feedback_item in feedbacks_contexto:
                if feedback_item.get('pontos_positivos'):
                    contexto_aprendizado += f"\
- Pontos positivos anteriores: {feedback_item['pontos_positivos']}"
                if feedback_item.get('pontos_melhorar'):
                    contexto_aprendizado += f"\
- Pontos a melhorar: {feedback_item['pontos_melhorar']}"

        status_text.text("‚öôÔ∏è Configurando an√°lise com IA...")
        progress_bar.progress(50)
        prompt = f'''
        Voc√™ √© um especialista em an√°lise de dados e marketing digital.
        Analise os seguintes dados de leads e forne√ßa insights relevantes para {plataforma} com o objetivo de {objetivo}.
        {contexto_aprendizado}
        Resumo dos dados:
        - Total de leads: {resumo_estatistico_global['total_leads']}
        - Amostra analisada: {resumo_estatistico_global['amostra_analisada']}
        - Colunas analisadas: {', '.join(resumo_estatistico_global['colunas_analisadas'])}
        Estat√≠sticas b√°sicas:
        {json.dumps(resumo_estatistico_global['estatisticas'], indent=2)}
        Dados da amostra:
        {df_str}
        Por favor, forne√ßa:
        1. An√°lise geral dos dados
        2. Insights espec√≠ficos para {plataforma}
        3. Recomenda√ß√µes de estrat√©gia para atingir o objetivo de {objetivo}
        4. Sugest√µes de segmenta√ß√£o dos leads
        5. Poss√≠veis abordagens personalizadas
        Mantenha a an√°lise clara e objetiva, focando em insights acion√°veis.
        '''
        status_text.text("ü§ñ Gerando an√°lise com IA (OpenAI)... ")
        progress_bar.progress(70)
        response_openai = client.chat.completions.create(
            model="gpt-4.1-mini", 
            messages=[{"role": "system", "content": "Voc√™ √© um especialista em an√°lise de dados e marketing digital."}, 
                      {"role": "user", "content": prompt}],
            temperature=0.7, max_tokens=800)
        
        tokens_consumidos = response_openai.usage.total_tokens
        username_para_tokens = st.session_state.get('username') # Usar .get() para seguran√ßa
        salvar_consumo_tokens(tokens_consumidos, "analise", username_para_tokens)
        
        status_text.text("‚ú® Finalizando e formatando an√°lise (OpenAI)... ")
        progress_bar.progress(90)
        analise_texto_ia = response_openai.choices[0].message.content.strip()
        tempo_processamento_ia = time.time() - tempo_inicio_global
        
        status_text.text("‚úÖ An√°lise (OpenAI) conclu√≠da!")
        progress_bar.progress(100)
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()
        return analise_texto_ia, tempo_processamento_ia

    except Exception as e_openai:
        status_text.text(f"‚ùå Erro na an√°lise com OpenAI: {e_openai}")
        progress_bar.progress(0)
        time.sleep(1)
        progress_bar.empty()
        status_text.empty()
        st.error(f"Erro ao analisar os leads com OpenAI: {e_openai}")
        return None, 0

def analisar_leads_csv(df, plataforma, objetivo):
    """
    Prepara dados, chama a an√°lise da OpenAI, salva os resultados e retorna a an√°lise, ID e tempo de processamento.
    """
    # Definir tempo_inicio aqui, fora do try, para garantir que sempre exista se a fun√ß√£o for chamada.
    # No entanto, para medir o tempo do bloco 'try', ele deve estar dentro.
    # Garantir que seja a primeira coisa no try.
    try:
        tempo_inicio = time.time() # Primeira linha DENTRO do try para medir a dura√ß√£o correta.
        
        colunas_relevantes = df.columns[:9]
        df_otimizado_para_stats = df[colunas_relevantes].copy()
        max_linhas_stats = 100 
        if len(df_otimizado_para_stats) > max_linhas_stats:
            df_otimizado_para_stats = df_otimizado_para_stats.sample(n=max_linhas_stats, random_state=42)

        resumo_estatistico = {
            "total_leads": len(df),
            "colunas_analisadas": list(colunas_relevantes),
            "amostra_analisada": len(df_otimizado_para_stats),
            "estatisticas": {}
        }
        for coluna in colunas_relevantes:
            if df_otimizado_para_stats[coluna].dtype in ['int64', 'float64']:
                resumo_estatistico["estatisticas"][coluna] = {
                    "media": df_otimizado_para_stats[coluna].mean(),
                    "mediana": df_otimizado_para_stats[coluna].median(),
                    "min": df_otimizado_para_stats[coluna].min(),
                    "max": df_otimizado_para_stats[coluna].max()
                }
            else:
                resumo_estatistico["estatisticas"][coluna] = {
                    "valores_mais_frequentes": df_otimizado_para_stats[coluna].value_counts().head().to_dict()
                }

        analise_gerada_pela_ia, tempo_processamento_openai = analisar_leads_csv_openai(
            df, plataforma, objetivo, tempo_inicio, resumo_estatistico # tempo_inicio √© passado aqui
        )

        if analise_gerada_pela_ia:
            analise_payload_para_salvar = {
                "plataforma": plataforma,
                "objetivo": objetivo,
                "total_leads": len(df), 
                "colunas": list(df.columns), 
                "analise": analise_gerada_pela_ia,
                "tempo_processamento": tempo_processamento_openai, # Este √© o tempo da IA
                "resumo_estatistico": resumo_estatistico,
                "tags": [] 
            }
            
            db_analise_id_uuid = salvar_analise_leads(analise_payload_para_salvar)
            
            if db_analise_id_uuid:
                # Retornar o texto da an√°lise, o ID do banco de dados e o tempo de processamento da IA
                return analise_gerada_pela_ia, db_analise_id_uuid, tempo_processamento_openai
            else:
                st.error("Falha ao salvar a an√°lise no banco de dados (depois da IA).")
                return None, None, None # Falha ao salvar no DB
        else:
            # Se analise_gerada_pela_ia for None (erro na OpenAI)
            return None, None, None # Erro na OpenAI

    except Exception as e:
        # Se o NameError for aqui, significa que 'tempo_inicio' n√£o foi definido antes de ser usado
        # na chamada de analisar_leads_csv_openai.
        st.error(f"Erro geral ao processar CSV e analisar leads: {e}")
        return None, None, None

def mostrar_historico_analises():
    """Mostra o hist√≥rico de an√°lises com op√ß√µes de feedback e m√©tricas"""
    st.subheader("üìö Hist√≥rico de An√°lises")
    
    # Filtro de tags
    st.sidebar.subheader("üîç Filtros")
    tags_selecionadas = []
    
    for categoria, tags in TAGS_PREDEFINIDAS.items():
        st.sidebar.write(f"**{categoria}:**")
        for tag in tags:
            # Criar uma chave √∫nica combinando categoria e tag
            chave_unica = f"filter_{categoria}_{tag}".replace(" ", "_").lower()
            if st.sidebar.checkbox(tag, key=chave_unica):
                tags_selecionadas.append(tag)
    
    historico_analises = carregar_historico_analises()
    
    if not historico_analises:
        st.info("Nenhuma an√°lise realizada ainda.")
    else:
        # Filtrar an√°lises por tags selecionadas
        if tags_selecionadas:
            historico_analises = [
                analise for analise in historico_analises
                if any(tag in analise.get('tags', []) for tag in tags_selecionadas)
            ]
        
        # Modificado para iterar diretamente e ajustar a numera√ß√£o
        for idx, analise in enumerate(historico_analises):
            # Modificado para exibir An√°lise #idx+1
            with st.expander(f"An√°lise #{idx + 1} - {analise['plataforma']} - {analise['data']}"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.write(f"**Plataforma:** {analise['plataforma']}")
                    st.write(f"**Objetivo:** {analise['objetivo']}")
                    st.write(f"**Data:** {analise['data']}")
                    st.write(f"**Total de Leads:** {analise['total_leads']}")
                    st.write("**Colunas Analisadas:**")
                    for col in analise['colunas']:
                        st.write(f"- {col}")
                
                with col2:
                    # Gerenciamento de Tags
                    st.write("**Tags:**")
                    tags_atuais = analise.get('tags', [])
                    
                    # Mostrar tags atuais
                    if tags_atuais:
                        for tag in tags_atuais:
                            st.write(f"üè∑Ô∏è {tag}")
                    
                    # Formul√°rio para adicionar novas tags
                    with st.form(f"tags_form_{idx}"):
                        novas_tags = []
                        for categoria, tags in TAGS_PREDEFINIDAS.items():
                            st.write(f"**{categoria}:**")
                            for tag in tags:
                                # Criar uma chave √∫nica para cada checkbox de tag
                                chave_unica = f"tag_{idx}_{categoria}_{tag}".replace(" ", "_").lower()
                                if st.checkbox(tag, key=chave_unica, value=tag in tags_atuais):
                                    novas_tags.append(tag)
                        
                        if st.form_submit_button("Atualizar Tags"):
                            if atualizar_tags_analise(analise['id'], novas_tags):
                                st.success("Tags atualizadas com sucesso!")
                                st.rerun()
                
                st.write("**An√°lise:**")
                st.markdown(analise['analise'])
                
                # Mostrar insights baseados nas tags
                if analise.get('tags'):
                    st.write("**üí° Insights Relacionados:**")
                    insights = gerar_insights_com_tags(analise, analise['tags'])
                    st.markdown(insights)
                
                # Se√ß√£o de Feedback
                st.subheader("üí≠ Feedback da An√°lise")
                feedback = carregar_feedback(analise['id'], analise.get('usuario_id')) # Passar usuario_id
                
                if feedback:
                    st.write("**Feedback Atual:**")
                    st.write(f"Nota: {'‚≠ê' * feedback['nota']}")
                    if feedback['pontos_positivos']:
                        st.write(f"**Pontos Positivos:** {feedback['pontos_positivos']}")
                    if feedback['pontos_melhorar']:
                        st.write(f"**Pontos a Melhorar:** {feedback['pontos_melhorar']}")
                    
                    if feedback.get('editado'):
                        st.write(f"**√öltima edi√ß√£o:** {feedback['ultima_edicao']}")
                    
                    # Bot√£o para editar feedback
                    if st.button("‚úèÔ∏è Editar Feedback", key=f"edit_feedback_{idx}"):
                        with st.form(f"edit_feedback_form_{idx}"):
                            novos_pontos_positivos = st.text_area(
                                "Pontos Positivos:",
                                value=feedback['pontos_positivos'],
                                key=f"edit_pos_{idx}"
                            )
                            novos_pontos_melhorar = st.text_area(
                                "Pontos a Melhorar:",
                                value=feedback['pontos_melhorar'],
                                key=f"edit_neg_{idx}"
                            )
                            nova_nota = st.slider(
                                "Nota:",
                                1, 5,
                                value=feedback['nota'],
                                key=f"edit_nota_{idx}"
                            )
                            if st.form_submit_button("Salvar Altera√ß√µes"):
                                novo_feedback = {
                                    "pontos_positivos": novos_pontos_positivos,
                                    "pontos_melhorar": novos_pontos_melhorar,
                                    "nota": nova_nota
                                }
                                if editar_feedback(analise['id'], novo_feedback):
                                    st.success("Feedback atualizado com sucesso!")
                                    st.rerun()
                else:
                    # Formul√°rio para novo feedback
                    with st.form(f"feedback_form_{idx}"):
                        pontos_positivos = st.text_area("Pontos Positivos:", 
                            placeholder="O que voc√™ achou mais √∫til nesta an√°lise?")
                        pontos_melhorar = st.text_area("Pontos a Melhorar:", 
                            placeholder="O que poderia ser melhorado nesta an√°lise?")
                        nota = st.slider("Nota da An√°lise:", 1, 5, 3)
                        if st.form_submit_button("Enviar Feedback"):
                            feedback_data = {
                                "pontos_positivos": pontos_positivos,
                                "pontos_melhorar": pontos_melhorar,
                                "nota": nota
                            }
                            if salvar_feedback(analise['id'], feedback_data):
                                st.success("Feedback enviado com sucesso!")
                                st.rerun()
                
                # Se√ß√£o de M√©tricas da Plataforma
                st.subheader("üìä M√©tricas da Plataforma")
                with st.form(f"metricas_form_{idx}"):
                    st.write(f"**M√©tricas para {analise['plataforma']}:**")
                    
                    if analise['plataforma'] == "Disparo de WhatsApp":
                        respostas = st.number_input("N√∫mero de Respostas:", min_value=0)
                        conversoes = st.number_input("N√∫mero de Convers√µes:", min_value=0)
                        total_disparos = st.number_input("Total de Disparos:", min_value=0)
                        
                        if st.form_submit_button("Salvar M√©tricas"):
                            metricas = {
                                "respostas": respostas,
                                "taxa_conversao": (conversoes / total_disparos * 100) if total_disparos > 0 else 0,
                                "total_disparos": total_disparos
                            }
                            if salvar_metricas_plataforma(analise['plataforma'], metricas):
                                st.success("M√©tricas salvas com sucesso!")
                    
                    elif analise['plataforma'] == "Email Marketing":
                        taxa_abertura = st.number_input("Taxa de Abertura (%):", min_value=0.0, max_value=100.0)
                        taxa_clique = st.number_input("Taxa de Clique (%):", min_value=0.0, max_value=100.0)
                        taxa_conversao = st.number_input("Taxa de Convers√£o (%):", min_value=0.0, max_value=100.0)
                        total_envios = st.number_input("Total de Envios:", min_value=0)
                        
                        if st.form_submit_button("Salvar M√©tricas"):
                            metricas = {
                                "taxa_abertura": taxa_abertura,
                                "taxa_clique": taxa_clique,
                                "taxa_conversao": taxa_conversao,
                                "total_envios": total_envios
                            }
                            if salvar_metricas_plataforma(analise['plataforma'], metricas):
                                st.success("M√©tricas salvas com sucesso!")
                    
                    elif analise['plataforma'] == "Conte√∫do para Redes Sociais (Feed)":
                        compartilhamentos = st.number_input("Compartilhamentos:", min_value=0)
                        likes = st.number_input("Likes:", min_value=0)
                        comentarios = st.number_input("Coment√°rios:", min_value=0)
                        alcance = st.number_input("Alcance:", min_value=0)
                        
                        if st.form_submit_button("Salvar M√©tricas"):
                            metricas = {
                                "compartilhamentos": compartilhamentos,
                                "likes": likes,
                                "comentarios": comentarios,
                                "alcance": alcance
                            }
                            if salvar_metricas_plataforma(analise['plataforma'], metricas):
                                st.success("M√©tricas salvas com sucesso!")
                    
                    elif analise['plataforma'] == "Conte√∫do para Redes Sociais (Stories)":
                        visualizacoes = st.number_input("Visualiza√ß√µes:", min_value=0)
                        respostas = st.number_input("Respostas:", min_value=0)
                        cliques = st.number_input("Cliques:", min_value=0)
                        alcance = st.number_input("Alcance:", min_value=0)
                        
                        if st.form_submit_button("Salvar M√©tricas"):
                            metricas = {
                                "visualizacoes": visualizacoes,
                                "respostas": respostas,
                                "cliques": cliques,
                                "alcance": alcance
                            }
                            if salvar_metricas_plataforma(analise['plataforma'], metricas):
                                st.success("M√©tricas salvas com sucesso!")
                    
                    elif analise['plataforma'] == "Copy para SMS":
                        taxa_clique = st.number_input("Taxa de Clique (%):", min_value=0.0, max_value=100.0)
                        taxa_conversao = st.number_input("Taxa de Convers√£o (%):", min_value=0.0, max_value=100.0)
                        total_envios = st.number_input("Total de Envios:", min_value=0)
                        
                        if st.form_submit_button("Salvar M√©tricas"):
                            metricas = {
                                "taxa_clique": taxa_clique,
                                "taxa_conversao": taxa_conversao,
                                "total_envios": total_envios
                            }
                            if salvar_metricas_plataforma(analise['plataforma'], metricas):
                                st.success("M√©tricas salvas com sucesso!")
                
                # Bot√£o para copiar a an√°lise
                if st.button("üìã Copiar An√°lise", key=f"copy_hist_{idx}"):
                    st.code(analise['analise'])
                    st.success("An√°lise copiada para a √°rea de transfer√™ncia!")

def carregar_feedback(analise_id, usuario_id_analise):
    """Carrega o feedback para uma an√°lise espec√≠fica do Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        user_id_logado = auth_user.user.id if auth_user and auth_user.user else None

        if not user_id_logado:
            st.info("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel carregar o feedback.")
            return None

        response = supabase.table('feedback')\
            .select('*')\
            .eq('analise_id', analise_id)\
            .eq('usuario_id', user_id_logado)\
            .order('created_at', desc=True)\
            .limit(1)\
            .maybe_single()\
            .execute()

        # Adicionar verifica√ß√£o para a pr√≥pria `response`
        if response is None:
            st.warning("A consulta ao Supabase para carregar feedback retornou None inesperadamente.")
            return None

        # Se .maybe_single() n√£o encontrar nada, response.data ser√° None.
        # A exce√ß√£o est√° sendo pega no bloco `except` abaixo.

        if response.data is None:
            return None 

        feedback_db = response.data
        
        historico_edicoes_str = feedback_db.get('historico_edicoes')
        historico_edicoes = []
        if isinstance(historico_edicoes_str, str) and historico_edicoes_str:
            try:
                historico_edicoes = json.loads(historico_edicoes_str)
            except json.JSONDecodeError:
                st.warning(f"Falha ao decodificar historico_edicoes para feedback da analise_id {analise_id}")
        elif isinstance(historico_edicoes_str, list):
             historico_edicoes = historico_edicoes_str

        return {
            "id": feedback_db.get('id'),
            "analise_id": feedback_db.get('analise_id'),
            "pontos_positivos": feedback_db.get('pontos_positivos'),
            "pontos_melhorar": feedback_db.get('pontos_melhorar'),
            "nota": feedback_db.get('nota'),
            "editado": feedback_db.get('editado', False),
            "ultima_edicao": feedback_db.get('ultima_edicao') or feedback_db.get('updated_at'), # Usar updated_at como fallback
            "historico_edicoes": historico_edicoes,
            "usuario_id": feedback_db.get('usuario_id')
        }

    except Exception as e:
        # Converter a exce√ß√£o para string para verificar se √© o erro "204 No Content"
        error_str = str(e)
        # O erro reportado √©: "{'message': 'Missing response', 'code': '204', ...}"
        # Verificar pela presen√ßa de 'code': '204' na string da exce√ß√£o.
        if "'code': '204'" in error_str or "PGRST116" in error_str: # PGRST116 √© o c√≥digo PostgREST para "item n√£o encontrado"
            # Este √© o caso em que nenhum feedback foi encontrado (HTTP 204 ou erro sem√¢ntico PGRST116).
            # N√£o √© um erro fatal para a aplica√ß√£o, apenas significa que n√£o h√° dados.
            return None
        else:
            # Se for qualquer outro erro, mostrar a mensagem de erro.
            st.error(f"Erro ao carregar feedback do Supabase: {e}")
            return None

def carregar_metricas():
    """Carrega e calcula as m√©tricas de performance do usu√°rio a partir do Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            st.info("Usu√°rio n√£o autenticado. M√©tricas gerais n√£o podem ser carregadas.")
            return {
                "total_analises": 0, "total_copies": 0, "tempo_medio_analise": 0.0,
                "media_notas": 0.0, "total_feedback": 0, "plataformas_mais_usadas": {},
                "objetivos_mais_comuns": {},
                "analises": []
            }
        user_id = auth_user.user.id

        metricas_calculadas = {
            "total_analises": 0,
            "total_copies": 0,
            "tempo_medio_analise": 0.0,
            "media_notas": 0.0,
            "total_feedback": 0,
            "plataformas_mais_usadas": defaultdict(int),
            "objetivos_mais_comuns": defaultdict(int),
            "analises": []
        }

        # 1. Total de An√°lises
        response_total_analises = supabase.table('analises_leads').select('id', count='exact').eq('usuario_id', user_id).execute()
        if response_total_analises.count is not None:
            metricas_calculadas["total_analises"] = response_total_analises.count

        # 2. Total de Copies
        response_total_copies = supabase.table('copies').select('id', count='exact').eq('usuario_id', user_id).execute()
        if response_total_copies.count is not None:
            metricas_calculadas["total_copies"] = response_total_copies.count

        # 3. Tempo M√©dio de An√°lise
        response_tempos_analise = supabase.table('metricas')\
            .select('tempo_processamento')\
            .eq('usuario_id', user_id)\
            .eq('tipo', 'analise')\
            .gt('tempo_processamento', 0)\
            .execute()
        if response_tempos_analise.data:
            tempos = [item['tempo_processamento'] for item in response_tempos_analise.data if item.get('tempo_processamento') is not None]
            if tempos:
                metricas_calculadas["tempo_medio_analise"] = sum(tempos) / len(tempos)

        # 4. M√©dia de Notas e 5. Total de Feedback
        response_feedbacks = supabase.table('feedback')\
            .select('nota')\
            .eq('usuario_id', user_id)\
            .execute()
        if response_feedbacks.data:
            notas = [item['nota'] for item in response_feedbacks.data if item.get('nota') is not None]
            metricas_calculadas["total_feedback"] = len(response_feedbacks.data)
            if notas:
                metricas_calculadas["media_notas"] = sum(notas) / len(notas)
        
        # 6. Plataformas Mais Usadas, 7. Objetivos Mais Comuns, 8. √öltimas An√°lises
        response_analises_detalhes = supabase.table('analises_leads')\
            .select('plataforma, objetivo, data, total_leads, tempo_processamento')\
            .eq('usuario_id', user_id)\
            .order('data', desc=True)\
            .limit(100) .execute() # Limitar para performance, dashboard mostra s√≥ top 5 anyway

        if response_analises_detalhes.data:
            for i, analise_item in enumerate(response_analises_detalhes.data):
                plataforma = analise_item.get('plataforma')
                objetivo = analise_item.get('objetivo')
                if plataforma:
                    metricas_calculadas["plataformas_mais_usadas"][plataforma] += 1
                if objetivo:
                    metricas_calculadas["objetivos_mais_comuns"][objetivo] += 1
                
                if i < 5: # Para a lista das 5 √∫ltimas an√°lises
                    data_iso = analise_item.get('data') 
                    data_formatada = str(data_iso) # Default para string original
                    if data_iso:
                        try:
                            if isinstance(data_iso, str):
                                dt_obj = datetime.fromisoformat(data_iso.replace('Z', '+00:00').replace('+0000', '+00:00'))
                                data_formatada = dt_obj.strftime("%d/%m/%Y %H:%M:%S")
                            elif isinstance(data_iso, datetime):
                                data_formatada = data_iso.strftime("%d/%m/%Y %H:%M:%S")
                        except ValueError: # Tentar outro formato se ISO falhar
                            try:
                                if isinstance(data_iso, str):
                                    dt_obj = datetime.strptime(data_iso, "%d/%m/%Y %H:%M:%S")
                                    data_formatada = dt_obj.strftime("%d/%m/%Y %H:%M:%S")
                            except ValueError:
                                pass # Mant√©m str(data_iso)
                    
                    metricas_calculadas["analises"].append({
                        "data": data_formatada,
                        "plataforma": plataforma,
                        "objetivo": objetivo,
                        "total_leads": analise_item.get('total_leads'),
                        "tempo_processamento": analise_item.get('tempo_processamento')
                    })
            
        # Converter defaultdicts para dicts para o output final
        metricas_calculadas["plataformas_mais_usadas"] = dict(metricas_calculadas["plataformas_mais_usadas"])
        metricas_calculadas["objetivos_mais_comuns"] = dict(metricas_calculadas["objetivos_mais_comuns"])

        return metricas_calculadas

    except Exception as e:
        st.error(f"Erro ao carregar m√©tricas gerais do Supabase: {e}")
        return {
            "total_analises": 0, "total_copies": 0, "tempo_medio_analise": 0.0,
            "media_notas": 0.0, "total_feedback": 0, "plataformas_mais_usadas": {},
            "objetivos_mais_comuns": {},
            "analises": []
        }

def gerar_dashboard():
    """Gera o dashboard com m√©tricas e visualiza√ß√µes importantes"""
    st.subheader("üìä Dashboard Geral")
    
    # Carregar dados
    metricas = carregar_metricas()
    metricas_plataforma = carregar_metricas_plataforma()
    historico_analises = carregar_historico_analises()
    consumo_tokens = carregar_consumo_tokens()
    
    if not metricas and not metricas_plataforma and not historico_analises and not (consumo_tokens and consumo_tokens['total_tokens'] > 0):
        st.info("Nenhum dado dispon√≠vel para exibir no dashboard. Comece a usar o sistema para gerar m√©tricas.")
        return
    
    # Layout em colunas para m√©tricas principais
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        total_analises = len(historico_analises) if historico_analises else 0
        st.metric("Total de An√°lises", total_analises)
    
    with col2:
        total_feedback = metricas.get('total_feedback', 0) if metricas else 0
        st.metric("Total de Feedback", total_feedback)
    
    with col3:
        media_notas = metricas.get('media_notas', 0) if metricas else 0
        st.metric("M√©dia de Notas", f"{media_notas:.1f} ‚≠ê")
    
    with col4:
        tempo_medio = metricas.get('tempo_medio_analise', 0) if metricas else 0
        st.metric("Tempo M√©dio de An√°lise", f"{tempo_medio:.1f}s")
    
    with col5:
        total_tokens = consumo_tokens.get('total_tokens', 0) if consumo_tokens else 0
        st.metric("Total de Tokens", f"{total_tokens:,}")
    
    # Adicionar se√ß√£o de consumo de tokens
    st.subheader("üî¢ Consumo de Tokens")
    col1, col2 = st.columns(2)
    
    with col1:
        if consumo_tokens:
            # Gr√°fico de pizza para distribui√ß√£o por opera√ß√£o
            fig = px.pie(
                values=[
                    consumo_tokens['por_operacao'].get('copy', 0),
                    consumo_tokens['por_operacao'].get('analise', 0),
                    consumo_tokens['por_operacao'].get('outro', 0) # Adicionar 'outro' se houver
                ],
                names=['Copy', 'An√°lise', 'Outro'],
                title='Distribui√ß√£o de Tokens por Opera√ß√£o'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        if consumo_tokens and consumo_tokens['historico']:
            # Preparar dados para o gr√°fico de linha
            historico = consumo_tokens['historico'][-10:]  # √öltimas 10 opera√ß√µes
            datas = [datetime.strptime(h['data'], "%d/%m/%Y %H:%M:%S") for h in historico]
            tokens = [h['tokens'] for h in historico]
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=datas,
                y=tokens,
                mode='lines+markers',
                name='Tokens Consumidos'
            ))
            
            fig.update_layout(
                title='Consumo de Tokens nas √öltimas Opera√ß√µes',
                xaxis_title='Data',
                yaxis_title='Tokens',
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # Gr√°ficos e an√°lises
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà An√°lises por Plataforma")
        if historico_analises:
            # Preparar dados para o gr√°fico
            plataformas = {}
            for analise in historico_analises:
                plataforma = analise['plataforma']
                plataformas[plataforma] = plataformas.get(plataforma, 0) + 1
            
            # Criar gr√°fico de barras
            fig = px.bar(
                x=list(plataformas.keys()),
                y=list(plataformas.values()),
                labels={'x': 'Plataforma', 'y': 'Quantidade'},
                title='Distribui√ß√£o de An√°lises por Plataforma'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("üéØ Objetivos Mais Comuns")
        if historico_analises:
            # Preparar dados para o gr√°fico
            objetivos = {}
            for analise in historico_analises:
                objetivo = analise['objetivo']
                objetivos[objetivo] = objetivos.get(objetivo, 0) + 1
            
            # Criar gr√°fico de pizza
            fig = px.pie(
                values=list(objetivos.values()),
                names=list(objetivos.keys()),
                title='Distribui√ß√£o de Objetivos'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # M√©tricas por Plataforma
    st.subheader("üìä M√©tricas por Plataforma")
    if metricas_plataforma:
        for plataforma, metricas in metricas_plataforma.items():
            with st.expander(f"üì± {plataforma}"):
                col1, col2, col3, col4 = st.columns(4)
                
                if plataforma == "Disparo de WhatsApp":
                    with col1:
                        st.metric("Respostas", metricas.get('respostas', 0))
                    with col2:
                        st.metric("Taxa de Convers√£o", f"{metricas.get('taxa_conversao', 0):.1f}%")
                    with col3:
                        st.metric("Total de Disparos", metricas.get('total_disparos', 0))
                
                elif plataforma == "Email Marketing":
                    with col1:
                        st.metric("Taxa de Abertura", f"{metricas.get('taxa_abertura', 0):.1f}%")
                    with col2:
                        st.metric("Taxa de Clique", f"{metricas.get('taxa_clique', 0):.1f}%")
                    with col3:
                        st.metric("Taxa de Convers√£o", f"{metricas.get('taxa_conversao', 0):.1f}%")
                    with col4:
                        st.metric("Total de Envios", metricas.get('total_envios', 0))
                
                elif plataforma == "Conte√∫do para Redes Sociais (Feed)":
                    with col1:
                        st.metric("Compartilhamentos", metricas.get('compartilhamentos', 0))
                    with col2:
                        st.metric("Likes", metricas.get('likes', 0))
                    with col3:
                        st.metric("Coment√°rios", metricas.get('comentarios', 0))
                    with col4:
                        st.metric("Alcance", metricas.get('alcance', 0))
                
                elif plataforma == "Conte√∫do para Redes Sociais (Stories)":
                    with col1:
                        st.metric("Visualiza√ß√µes", metricas.get('visualizacoes', 0))
                    with col2:
                        st.metric("Respostas", metricas.get('respostas', 0))
                    with col3:
                        st.metric("Cliques", metricas.get('cliques', 0))
                    with col4:
                        st.metric("Alcance", metricas.get('alcance', 0))
                
                elif plataforma == "Copy para SMS":
                    with col1:
                        st.metric("Taxa de Clique", f"{metricas.get('taxa_clique', 0):.1f}%")
                    with col2:
                        st.metric("Taxa de Convers√£o", f"{metricas.get('taxa_conversao', 0):.1f}%")
                    with col3:
                        st.metric("Total de Envios", metricas.get('total_envios', 0))
    
    # An√°lise Temporal
    st.subheader("‚è≥ An√°lise Temporal")
    if historico_analises:
        # Preparar dados para o gr√°fico
        datas = []
        for analise in historico_analises:
            try:
                data = datetime.strptime(analise['data'], "%d/%m/%Y %H:%M:%S")
                datas.append(data)
            except:
                continue
        
        if datas:
            # Criar gr√°fico de linha
            datas.sort()
            contagem = list(range(1, len(datas) + 1))
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=datas,
                y=contagem,
                mode='lines+markers',
                name='An√°lises'
            ))
            
            fig.update_layout(
                title='Evolu√ß√£o do N√∫mero de An√°lises',
                xaxis_title='Data',
                yaxis_title='N√∫mero de An√°lises',
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # Tags Mais Utilizadas
    st.subheader("üè∑Ô∏è Tags Mais Utilizadas")
    if historico_analises:
        # Contar frequ√™ncia de tags
        tags_frequencia = {}
        for analise in historico_analises:
            for tag in analise.get('tags', []):
                tags_frequencia[tag] = tags_frequencia.get(tag, 0) + 1
        
        if tags_frequencia:
            # Criar gr√°fico de barras horizontais
            fig = px.bar(
                x=list(tags_frequencia.values()),
                y=list(tags_frequencia.keys()),
                orientation='h',
                labels={'x': 'Frequ√™ncia', 'y': 'Tag'},
                title='Frequ√™ncia de Tags'
            )
            st.plotly_chart(fig, use_container_width=True)

# Adicionar ap√≥s as configura√ß√µes iniciais
def salvar_consumo_tokens(tokens_consumidos, tipo_operacao, username_email=None):
    try:
        usuario_id_supabase = None
        if username_email: # username_email √© o email do usu√°rio logado
            auth_user = supabase.auth.get_user() # Tenta obter o usu√°rio da sess√£o Supabase
            if auth_user and auth_user.user:
                usuario_id_supabase = auth_user.user.id
            else:
                # Fallback se n√£o conseguir o user da sess√£o auth (pode acontecer se o token expirou)
                # Tenta buscar pelo email, assumindo que st.session_state.username cont√©m o email
                if 'username' in st.session_state and st.session_state.username:
                     user_lookup = supabase.table('users').select('id').eq('email', st.session_state.username).execute()
                     if user_lookup.data:
                         usuario_id_supabase = user_lookup.data[0]['id']

        if not usuario_id_supabase and 'username' in st.session_state and st.session_state.username:
             st.warning(f"N√£o foi poss√≠vel determinar o ID do usu√°rio Supabase para {st.session_state.username} ao salvar consumo de tokens. Tentando com o email como ID.")

        # Formatar dados para o Supabase
        payload = {
            "tipo": tipo_operacao,
            "total_tokens": tokens_consumidos,
            "plataforma": "copy" if tipo_operacao == "copy" else "analise",
            "tempo_processamento": 0, 
            "usuario_id": usuario_id_supabase, # Pode ser None se n√£o encontrado
            "data": datetime.now().isoformat()
        }

        # Salvar no Supabase
        response = supabase.table('metricas').insert(payload).execute()
        
        if response.data:
            return True
        else:
            st.error(f"Erro ao salvar consumo de tokens no Supabase: {response.error.message if response.error else 'Erro desconhecido'}")
            return False
    except Exception as e:
        st.error(f"Erro ao salvar consumo de tokens: {e}")
        return False

# Adicionar ap√≥s as configura√ß√µes iniciais
def salvar_metricas(metricas_data):
    """Salva as m√©tricas de performance no Supabase"""
    try:
        usuario_id_supabase = None
        if 'username' in st.session_state and st.session_state.username: # username √© o email
            auth_user = supabase.auth.get_user()
            if auth_user and auth_user.user:
                usuario_id_supabase = auth_user.user.id
            # metricas_data['usuario_id'] n√£o √© usado diretamente aqui, mas pego de st.session_state

        payload = {
            "data": datetime.now().isoformat(),
            "usuario_id": usuario_id_supabase # Pode ser None
        }

        if "analise" in metricas_data:
            analise = metricas_data["analise"]
            payload.update({
                "tipo": "analise",
                "plataforma": analise["plataforma"],
                "total_tokens": 0, # Tokens de an√°lise s√£o salvos por salvar_consumo_tokens
                "tempo_processamento": analise["tempo_processamento"]
            })
        elif "copy" in metricas_data: # 'copy' n√£o parece ser um tipo usado aqui atualmente
            payload.update({
                "tipo": "copy_gerada", # Mudar para tipo distinto se necess√°rio
                "plataforma": "copy_geral", # Ajustar conforme necessidade
                "total_tokens": 0, 
                "tempo_processamento": 0
            })
        elif "feedback" in metricas_data:
            # feedback = metricas_data["feedback"] # N√£o usado diretamente
            payload.update({
                "tipo": "feedback_recebido", # Mudar para tipo distinto
                "plataforma": "feedback_sistema", # Ajustar
                "total_tokens": 0,
                "tempo_processamento": 0,
            })
        else:
            st.warning("Tipo de m√©trica desconhecido para salvar.")
            return False


        # Salvar no Supabase
        response = supabase.table('metricas').insert(payload).execute()
        
        if response.data:
            return True
        else:
            st.error(f"Erro ao salvar m√©tricas no Supabase: {response.error.message if response.error else 'Erro desconhecido'}")
            return False
    except Exception as e:
        st.error(f"Erro ao salvar m√©tricas: {e}")
        return False

def carregar_metricas_plataforma():
    """Carrega as m√©tricas espec√≠ficas da plataforma mais recentes do Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            # st.error("Usu√°rio n√£o autenticado. N√£o √© poss√≠vel carregar m√©tricas da plataforma.")
            return {} 
        user_id = auth_user.user.id

        # Buscar todas as m√©tricas de plataforma para o usu√°rio
        response = supabase.table('metricas_plataforma') \
            .select('plataforma, metricas, data') \
            .eq('usuario_id', user_id) \
            .order('data', desc=True) \
            .execute()

        metricas_recentes_por_plataforma = {}
        if response.data:
            for item in response.data:
                plataforma = item['plataforma']
                # Se ainda n√£o temos a m√©trica mais recente para esta plataforma, adicionamos
                if plataforma not in metricas_recentes_por_plataforma:
                    metricas_db = item.get('metricas')
                    if isinstance(metricas_db, str):
                        try:
                            metricas_recentes_por_plataforma[plataforma] = json.loads(metricas_db)
                        except json.JSONDecodeError:
                            st.warning(f"Falha ao decodificar JSON de m√©tricas para a plataforma {plataforma}")
                            metricas_recentes_por_plataforma[plataforma] = METRICAS_POR_PLATAFORMA.get(plataforma, {}) # Fallback para estrutura padr√£o
                    elif isinstance(metricas_db, dict):
                        metricas_recentes_por_plataforma[plataforma] = metricas_db
                    else:
                        metricas_recentes_por_plataforma[plataforma] = METRICAS_POR_PLATAFORMA.get(plataforma, {}) # Fallback
            return metricas_recentes_por_plataforma
        return {} # Retornar dict vazio se n√£o houver dados, para consist√™ncia

    except Exception as e:
        st.error(f"Erro ao carregar m√©tricas da plataforma do Supabase: {e}")
        return {} # Retornar dict vazio em caso de erro

def carregar_consumo_tokens():
    """Carrega o consumo de tokens do usu√°rio a partir do Supabase."""
    try:
        auth_user = supabase.auth.get_user()
        if not (auth_user and auth_user.user):
            return {
                "total_tokens": 0,
                "historico": [],
                "por_operacao": {"copy": 0, "analise": 0, "outro": 0}
            }
        user_id = auth_user.user.id

        response = supabase.table('metricas')\
            .select('total_tokens, tipo, plataforma, data')\
            .eq('usuario_id', user_id)\
            .gt('total_tokens', 0) \
            .order('data', desc=True)\
            .execute()

        consumo = {
            "total_tokens": 0,
            "historico": [],
            "por_operacao": defaultdict(int) 
        }

        if response.data:
            for item in response.data:
                tokens = item.get('total_tokens', 0)
                consumo["total_tokens"] += tokens
                
                data_iso = item.get('data')
                data_formatada = "Data Desconhecida"
                if data_iso:
                    try:
                        data_formatada = datetime.fromisoformat(data_iso.replace('Z', '+00:00')).strftime("%d/%m/%Y %H:%M:%S")
                    except ValueError:
                        try:
                            data_formatada = datetime.strptime(data_iso, "%d/%m/%Y %H:%M:%S").strftime("%d/%m/%Y %H:%M:%S")
                        except ValueError:
                            data_formatada = str(data_iso)
                
                consumo["historico"].append({
                    "tokens": tokens,
                    "tipo": item.get('tipo', 'desconhecido'),
                    "plataforma": item.get('plataforma'),
                    "data": data_formatada
                })
                
                tipo_op = item.get('tipo', 'outro').lower()
                if tipo_op in ["copy", "analise"]:
                    consumo["por_operacao"][tipo_op] += tokens
                else:
                    consumo["por_operacao"]['outro'] += tokens
            
            consumo["historico"].reverse() 

        consumo["por_operacao"] = {
            "copy": consumo["por_operacao"]['copy'],
            "analise": consumo["por_operacao"]['analise'],
            "outro": consumo["por_operacao"]['outro']
        }
        return consumo
        
    except Exception as e:
        st.error(f"Erro ao carregar consumo de tokens do Supabase: {e}")
        return {
            "total_tokens": 0,
            "historico": [],
            "por_operacao": {"copy": 0, "analise": 0, "outro": 0}
        }

# --- Interface Streamlit ---
st.set_page_config(page_title="Gerador de Copy Mencare", layout="wide")

# Verificar autentica√ß√£o
if not st.session_state.autenticado:
    login()
else:
    # Inicializar st.session_state se n√£o existir
    if 'generated_copy' not in st.session_state:
        st.session_state.generated_copy = ""
    if 'form_data' not in st.session_state:
        st.session_state.form_data = {}
    if 'historico' not in st.session_state:
        st.session_state.historico = []
    if 'analise_leads' not in st.session_state:
        st.session_state.analise_leads = None

    # Barra superior com informa√ß√µes do usu√°rio e bot√£o de logout
    col1, col2 = st.columns([6, 1])
    with col1:
        st.title("ü§ñ Gerador de Copy Mencare ‚úçÔ∏è")
    with col2:
        if st.button("üö™ Logout"):
            try:
                # Adicionar logout do Supabase
                supabase.auth.sign_out()
                st.success("Logout realizado com sucesso!")
            except Exception as e:
                st.error(f"Erro ao fazer logout do Supabase: {e}")
            
            # Limpar estado da sess√£o do Streamlit
            st.session_state.autenticado = False
            st.session_state.username = None
            st.session_state.login_success = False
            # Limpar outros dados de sess√£o que dependem do usu√°rio, se houver
            st.session_state.generated_copy = ""
            st.session_state.form_data = {}
            st.session_state.historico = []
            st.session_state.analise_leads = None
            if 'analise_id' in st.session_state:
                del st.session_state['analise_id']

            st.rerun()

    # Criar as abas
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìù Gerar Copy", "üìö Hist√≥rico", "üìä An√°lise de Leads", "üìà M√©tricas", "üéØ Dashboard"])

    with tab1:
        st.markdown("Preencha os campos abaixo para gerar sua copy e, opcionalmente, salv√°-la no Baserow.")

        with st.sidebar:
            st.header("‚öôÔ∏è Configura√ß√µes da Copy")
            plataforma_opcoes = [
                "Disparo de WhatsApp",
                "Email Marketing",
                "Conte√∫do para Redes Sociais (Feed)",
                "Conte√∫do para Redes Sociais (Stories)",
                "Copy para SMS"
            ]
            plataforma = st.selectbox("Selecione a Plataforma:", plataforma_opcoes)
            
            # Mostrar limite de tokens para a plataforma selecionada
            tokens_limite = TOKENS_POR_PLATAFORMA.get(plataforma, 300)
            st.info(f"Limite de tokens para esta plataforma: {tokens_limite}")
            
            objetivo = st.text_input("üéØ Objetivo da Copy:", placeholder="Ex: Gerar leads, Vender produto X, Aumentar engajamento")
            publico_alvo = st.text_input("üë• P√∫blico-Alvo:", placeholder="Ex: Jovens de 18-25 anos interessados em tecnologia")
            produto_servico = st.text_input("üõçÔ∏è Produto/Servi√ßo:", placeholder="Ex: Curso online de Python, Consultoria de Marketing Digital")
            tom_de_voz_opcoes = ["Formal", "Informal", "Amig√°vel", "Persuasivo", "Divertido", "Urgente"]
            tom_de_voz = st.selectbox("üó£Ô∏è Tom de Voz:", tom_de_voz_opcoes)
            cta = st.text_input("üì¢ Call to Action (CTA):", placeholder="Ex: Compre agora, Saiba mais, Inscreva-se j√°")
            informacoes_adicionais = st.text_area("‚ÑπÔ∏è Informa√ß√µes Adicionais (Opcional):", placeholder="Ex: Mencionar promo√ß√£o de 20% OFF, destacar benef√≠cio Y")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("üìù Campos para Gera√ß√£o")
            if st.button("‚ú® Gerar Copy Agora!", type="primary", use_container_width=True):
                if not all([plataforma, objetivo, publico_alvo, produto_servico, tom_de_voz, cta]):
                    st.warning("Por favor, preencha todos os campos obrigat√≥rios antes de gerar a copy.")
                else:
                    with st.spinner("Gerando sua copy com IA... Aguarde! üß†"):
                        copy_gerada = gerar_copy_openai(
                            plataforma, objetivo, publico_alvo, produto_servico, tom_de_voz, cta, informacoes_adicionais
                        )
                        if copy_gerada:
                            st.session_state.generated_copy = copy_gerada
                            st.session_state.form_data = {
                                "plataforma": plataforma,
                                "objetivo": objetivo,
                                "publico_alvo": publico_alvo,
                                "produto_servico": produto_servico,
                                "tom_de_voz": tom_de_voz,
                                "cta": cta,
                                "copy_gerada": copy_gerada,
                                "data_geracao": datetime.now().strftime("%d/%m/%Y %H:%M:%S")
                            }
                            # Adicionar ao hist√≥rico
                            st.session_state.historico.append(st.session_state.form_data)
                        else:
                            st.session_state.generated_copy = ""
                            st.session_state.form_data = {}

        with col2:
            st.subheader("üìÑ Copy Gerada")
            if st.session_state.generated_copy:
                st.text_area("Resultado:", st.session_state.generated_copy, height=300)
                if SUPABASE_URL and SUPABASE_KEY:
                    if st.button("üíæ Salvar Copy no Supabase", use_container_width=True):
                        with st.spinner("Salvando no Supabase..."):
                            if st.session_state.form_data:
                                salvar_no_supabase(st.session_state.form_data)
                            else:
                                st.error("Nenhuma copy gerada para salvar.")
                elif st.session_state.generated_copy:
                    st.info("Configure as vari√°veis de ambiente do Supabase para habilitar o salvamento.")
            else:
                st.info("A copy gerada aparecer√° aqui.")

    with tab2:
        st.subheader("üìö Hist√≥rico de Copies")
        
        if not st.session_state.historico:
            st.info("Nenhuma copy gerada ainda. O hist√≥rico aparecer√° aqui ap√≥s gerar algumas copies.")
        else:
            # Mostrar hist√≥rico em ordem reversa (mais recente primeiro)
            for idx, item in enumerate(reversed(st.session_state.historico)):
                with st.expander(f"Copy #{len(st.session_state.historico) - idx} - {item['plataforma']} - {item['data_geracao']}"):
                    st.write(f"**Plataforma:** {item['plataforma']}")
                    st.write(f"**Objetivo:** {item['objetivo']}")
                    st.write(f"**P√∫blico-Alvo:** {item['publico_alvo']}")
                    st.write(f"**Produto/Servi√ßo:** {item['produto_servico']}")
                    st.write(f"**Tom de Voz:** {item['tom_de_voz']}")
                    st.write(f"**CTA:** {item['cta']}")
                    st.write("**Copy Gerada:**")
                    st.text_area("", item['copy_gerada'], height=200, key=f"copy_{idx}")
                    
                    # Bot√£o para copiar a copy
                    if st.button("üìã Copiar Copy", key=f"copy_btn_{idx}"):
                        st.code(item['copy_gerada'])
                        st.success("Copy copiada para a √°rea de transfer√™ncia!")

    with tab3:
        st.subheader("üìä An√°lise de Leads via CSV")
        
        # Configura√ß√µes da an√°lise
        col1, col2 = st.columns(2)
        
        with col1:
            plataforma_analise = st.selectbox(
                "Selecione a Plataforma para An√°lise:",
                ["Disparo de WhatsApp", "Email Marketing", "Conte√∫do para Redes Sociais (Feed)", 
                 "Conte√∫do para Redes Sociais (Stories)", "Copy para SMS"],
                key="plataforma_analise"
            )
        
        with col2:
            objetivo_analise = st.text_input(
                "Objetivo da An√°lise:",
                placeholder="Ex: Aumentar convers√µes, Melhorar engajamento, Gerar vendas",
                key="objetivo_analise"
            )
        
        # Upload de m√∫ltiplos arquivos CSV
        uploaded_files = st.file_uploader(
            "Escolha um ou mais arquivos CSV com seus leads", 
            type=['csv'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            try:
                # Lista para armazenar todos os DataFrames
                dfs = []
                total_leads = 0
                
                # Processar cada arquivo
                for uploaded_file in uploaded_files:
                    df = pd.read_csv(uploaded_file)
                    dfs.append(df)
                    total_leads += len(df)
                
                # Mostrar preview dos dados
                st.subheader("üìã Preview dos Dados")
                
                # Criar abas para cada arquivo
                tabs = st.tabs([f"Arquivo {i+1}" for i in range(len(dfs))])
                
                for i, tab in enumerate(tabs):
                    with tab:
                        st.write(f"**Arquivo {i+1}:** {uploaded_files[i].name}")
                        st.write(f"Total de leads neste arquivo: {len(dfs[i])}")
                        st.dataframe(dfs[i].head())
                        st.write("Colunas dispon√≠veis:")
                        for col in dfs[i].columns:
                            st.write(f"- {col}")
                
                # Mostrar informa√ß√µes b√°sicas do dataset combinado
                st.subheader("‚ÑπÔ∏è Informa√ß√µes do Dataset Combinado")
                st.write(f"Total de leads em todos os arquivos: {total_leads}")
                
                # Bot√£o para iniciar an√°lise
                if st.button("üîç Iniciar An√°lise", type="primary"):
                    if not objetivo_analise:
                        st.warning("Por favor, defina um objetivo para a an√°lise.")
                    else:
                        with st.spinner("Analisando seus leads... Isso pode levar alguns minutos."):
                            df_combinado = pd.concat(dfs, ignore_index=True)
                            df_combinado = df_combinado.drop_duplicates()
                            
                            # Ajustar a chamada para receber tr√™s valores
                            analise_texto_resultado, analise_db_id_retornado, tempo_proc_openai_retornado = analisar_leads_csv(
                                df_combinado, plataforma_analise, objetivo_analise
                            )
                            
                            if analise_texto_resultado and analise_db_id_retornado:
                                st.session_state.analise_leads_conteudo_ia = analise_texto_resultado
                                st.session_state.analise_id_atual_db = analise_db_id_retornado
                                st.success("An√°lise conclu√≠da e salva no hist√≥rico!")
                                
                                # Salvar m√©tricas usando o tempo de processamento retornado
                                # A fun√ß√£o salvar_metricas atualmente define "total_tokens": 0 e "tempo_processamento" 
                                # para "analise" baseado no que √© passado.
                                metricas_payload_analise = {
                                    "data": datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
                                    "plataforma": plataforma_analise,
                                    "objetivo": objetivo_analise,
                                    "total_leads": len(df_combinado),
                                    "tempo_processamento": tempo_proc_openai_retornado # Passar o tempo correto
                                }
                                salvar_metricas({"analise": metricas_payload_analise})

                            elif analise_texto_resultado is None and analise_db_id_retornado is None:
                                # Erro j√° foi mostrado por analisar_leads_csv ou sua helper
                                st.session_state.analise_leads_conteudo_ia = None
                                st.session_state.analise_id_atual_db = None
                            else: # Caso inesperado
                                st.error("Ocorreu um erro inesperado durante a an√°lise.")
                                st.session_state.analise_leads_conteudo_ia = None
                                st.session_state.analise_id_atual_db = None
                
                # Mostrar resultados da an√°lise (usando a nova chave de session_state)
                if st.session_state.get('analise_leads_conteudo_ia'):
                    st.subheader("üìä Resultados da An√°lise")
                    st.markdown(st.session_state.analise_leads_conteudo_ia)
                    
                    # Se√ß√£o de feedback - s√≥ mostrar se a an√°lise foi salva e temos um ID de DB
                    if st.session_state.get('analise_id_atual_db'):
                        st.subheader("üí≠ Feedback da An√°lise")
                        # Usar uma chave de formul√°rio √∫nica para evitar conflitos
                        with st.form(f"feedback_form_nova_analise_{st.session_state.analise_id_atual_db}"):
                            pontos_positivos = st.text_area("Pontos Positivos:", 
                                placeholder="O que voc√™ achou mais √∫til nesta an√°lise?", key=f"fp_pos_{st.session_state.analise_id_atual_db}")
                            pontos_melhorar = st.text_area("Pontos a Melhorar:", 
                                placeholder="O que poderia ser melhorado nesta an√°lise?", key=f"fp_neg_{st.session_state.analise_id_atual_db}")
                            nota = st.slider("Nota da An√°lise:", 1, 5, 3, key=f"fp_nota_{st.session_state.analise_id_atual_db}")
                            feedback_submit = st.form_submit_button("Enviar Feedback")
                            
                            if feedback_submit:
                                feedback_data_payload = {
                                    "pontos_positivos": pontos_positivos,
                                    "pontos_melhorar": pontos_melhorar,
                                    "nota": nota
                                }
                                # Usar o ID UUID do banco de dados armazenado na session_state
                                if salvar_feedback(st.session_state.analise_id_atual_db, feedback_data_payload):
                                    st.success("Feedback enviado com sucesso! Obrigado por ajudar a melhorar nossas an√°lises.")
                                else:
                                    st.error("Falha ao enviar o feedback.")
                    else:
                        if st.session_state.get('analise_leads_conteudo_ia'): # S√≥ mostrar esta msg se houve tentativa de an√°lise
                            st.info("A an√°lise precisa ser salva com sucesso no banco de dados antes de adicionar feedback.")
                    
                    if st.button("üìã Copiar An√°lise (Resultados)", key=f"copiar_analise_nova_{st.session_state.get('analise_id_atual_db', '')}"):
                        st.code(st.session_state.analise_leads_conteudo_ia)
                        st.success("An√°lise copiada para a √°rea de transfer√™ncia!")
            
            except Exception as e:
                st.error(f"Erro ao processar os arquivos CSV: {e}")
                st.info("Certifique-se de que os arquivos est√£o no formato CSV v√°lido e cont√™m dados estruturados.")
        else:
            st.info("Fa√ßa upload de um ou mais arquivos CSV para come√ßar a an√°lise.")

        mostrar_historico_analises()

    with tab4:
        st.subheader("üìà M√©tricas de Performance")
        
        metricas = carregar_metricas()
        
        if not metricas:
            st.info("Nenhuma m√©trica dispon√≠vel ainda. Comece a usar o sistema para gerar m√©tricas.")
        else:
            # M√©tricas gerais
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total de An√°lises", metricas["total_analises"])
                st.metric("Total de Copies", metricas["total_copies"])
            
            with col2:
                st.metric("Tempo M√©dio de An√°lise", f"{metricas['tempo_medio_analise']:.2f}s")
                st.metric("M√©dia de Notas", f"{metricas['media_notas']:.1f} ‚≠ê")
            
            with col3:
                st.metric("Total de Feedback", metricas["total_feedback"])
            
            # Gr√°ficos e an√°lises detalhadas
            st.subheader("üìä An√°lise Detalhada")
            
            # Plataformas mais usadas
            st.write("**Plataformas Mais Utilizadas**")
            plataformas_df = pd.DataFrame(
                list(metricas["plataformas_mais_usadas"].items()),
                columns=["Plataforma", "Quantidade"]
            )
            st.bar_chart(plataformas_df.set_index("Plataforma"))
            
            # Objetivos mais comuns
            st.write("**Objetivos Mais Comuns**")
            objetivos_df = pd.DataFrame(
                list(metricas["objetivos_mais_comuns"].items()),
                columns=["Objetivo", "Quantidade"]
            )
            st.bar_chart(objetivos_df.set_index("Objetivo"))
            
            # √öltimas an√°lises
            st.subheader("üìã √öltimas An√°lises")
            if metricas["analises"]:
                ultimas_analises = pd.DataFrame(metricas["analises"][-5:])
                st.dataframe(ultimas_analises[["data", "plataforma", "objetivo", "total_leads", "tempo_processamento"]])
            
            # Exportar m√©tricas
            if st.button("üì• Exportar M√©tricas"):
                metricas_json = json.dumps(metricas, indent=4)
                st.download_button(
                    label="Baixar M√©tricas",
                    data=metricas_json,
                    file_name=f"metricas_{st.session_state.username}_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json"
                )

    with tab5:
        gerar_dashboard()

    st.markdown("---")